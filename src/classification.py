import os
import pandas as pd

def load_processed_data(export_filename="processed_go.csv"):
    """
    Loads processed gene ontology data from the CSV file in the output folder.
    
    This processed file is expected to be generated by the ingestion pipeline after
    running process_ontology.py. It must contain at least the columns 'gene',
    'pathways', and 'interactions'.
    
    Parameters:
        export_filename (str): Name of the processed CSV file.
        
    Returns:
        pandas.DataFrame: DataFrame containing the processed data.
        
    Raises:
        FileNotFoundError: If the processed CSV file is not found.
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(base_dir, "..", "output", export_filename)
    
    if not os.path.exists(output_path):
        raise FileNotFoundError(f"Processed file not found at: {output_path}")
    
    print(f"Loading processed data from: {output_path}")
    data = pd.read_csv(output_path)
    return data

def compute_impact_index(data):
    """
    Calculates the 'functional impact index' for each gene in the dataset.
    
    The index is defined as the sum of 'pathways' and 'interactions'.
    This function expects the DataFrame to be fully processed (i.e., by process_ontology.py)
    and to include the required columns.
    
    Parameters:
        data (pandas.DataFrame): Processed DataFrame containing at least 'pathways'
                                 and 'interactions' columns.
    
    Returns:
        pandas.DataFrame: DataFrame with an added column 'impact_index'.
        
    Raises:
        KeyError: If the required columns are not present.
    """
    required_columns = ['pathways', 'interactions']
    for col in required_columns:
        if col not in data.columns:
            raise KeyError(f"Missing required column: {col}")
    
    data['impact_index'] = data['pathways'] + data['interactions']
    return data

def run_classification_pipeline():
    """
    Runs the classification pipeline:
      1. Loads the fully processed data from the output folder (processed_go.csv).
      2. Computes the functional impact index.
      
    Returns:
        pandas.DataFrame: DataFrame with the computed 'impact_index'.
    """
    # Load the processed CSV data (output from process_ontology.py via ingestion.py)
    data = load_processed_data()
    # Compute the impact index
    classified_data = compute_impact_index(data)
    return classified_data

# Example usage:
if __name__ == "__main__":
    try:
        result_df = run_classification_pipeline()
        print("Classification complete. Data with impact index:")
        print(result_df.head())
    except Exception as e:
        print(f"Error during classification: {e}")
